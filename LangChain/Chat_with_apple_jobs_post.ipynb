{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CodeAlchemyAI/AI-Notebooks/blob/main/LangChain/chat_with_apple_jobs_post.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This example demonstrates how to create a Q&A system using job postings from Apple's official jobs site: https://jobs.apple.com."
      ],
      "metadata": {
        "id": "W39zoi2XqYk4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain.document_loaders import UnstructuredURLLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain import OpenAI\n",
        "from langchain.chains import RetrievalQAWithSourcesChain\n",
        "import pinecone \n",
        "import os"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dop7DJTqFHz",
        "outputId": "e20bba75-2620-4626-aedc-45143af0d9f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qTs1u8E1HcvV"
      },
      "outputs": [],
      "source": [
        "# Let's install necessary libraries\n",
        "!pip install  langchain\n",
        "!pip install openai\n",
        "!pip install BeautifulSoup\n",
        "!pip install requests\n",
        "!pip install unstructured\n",
        "!pip install pdf2image\n",
        "!pip install chromadb\n",
        "!pip install pinecone-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REOLBTBPs43r"
      },
      "source": [
        "First, let's create a function to retrieve all the URLs from jobs.apple.com."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbBkMZm6syn-"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"sk-OPENAI-KEY\"\n",
        "\n",
        "embeddings = OpenAIEmbeddings()\n",
        "\n",
        "\n",
        "# Base URL\n",
        "base_url = \"https://jobs.apple.com\"\n",
        "\n",
        "# Store all the links\n",
        "all_links = []\n",
        "\n",
        "# Loop through all pages\n",
        "for i in range(1, 2):\n",
        "    # Get page content\n",
        "    url = f\"{base_url}/en-us/search?page={i}\"\n",
        "    response = requests.get(url)\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "    # Find all 'a' elements with the specific class\n",
        "    a_elements = soup.find_all('a', class_='table--advanced-search__title')\n",
        "\n",
        "    # Extract and append the href attribute of each 'a' element to the list\n",
        "    for a in a_elements:\n",
        "        link = base_url + a['href']\n",
        "        all_links.append(link)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Init the Pinecone database"
      ],
      "metadata": {
        "id": "1rdursminKVa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "VV2cParBBmSz"
      },
      "outputs": [],
      "source": [
        "PINECONE_API_KEY =\"PINECONE-API-KEY\"\n",
        "PINECONE_ENV='asia-northeast1-gcp'\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_ENV\n",
        ")\n",
        "index_name = \"apple\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Iterate through all links, load page text, and transform this text into vectors. Save these vectors to Pinecone. This process is performed in batches to enhance efficiency."
      ],
      "metadata": {
        "id": "0UvW1fzEnTqB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "b0qaJum3-RPd"
      },
      "outputs": [],
      "source": [
        "def process_batch(batch):\n",
        "    loader = UnstructuredURLLoader(urls=batch)\n",
        "    documents = loader.load()\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    Pinecone.from_documents(docs, embeddings, index_name=index_name)\n",
        "\n",
        "batch = []\n",
        "batch_limit = 100\n",
        "\n",
        "for i, link in all_links:\n",
        "    batch.append(link)\n",
        "    if len(batch) >= batch_limit:\n",
        "        process_batch(batch)\n",
        "        batch = []\n",
        "        \n",
        "# Processing the remaining batch (if it's not empty)\n",
        "if batch:\n",
        "    process_batch(batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now interact with the data using the RetrievalQAWithSourcesChain."
      ],
      "metadata": {
        "id": "hrG8MeHyryCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_field = \"text\"\n",
        "\n",
        "index = pinecone.Index(index_name)\n",
        "embed = OpenAIEmbeddings()\n",
        "vectorstore = Pinecone(\n",
        "    index, embed.embed_query, text_field\n",
        ")\n",
        "chain = RetrievalQAWithSourcesChain.from_chain_type(OpenAI(temperature=0), chain_type=\"stuff\", retriever=vectorstore.as_retriever())\n",
        "chain({\"question\": \"Is Apple working on a large language model?\"}, return_only_outputs=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_cQky9wk6cj",
        "outputId": "4b41e8fd-3aff-48ef-a5c8-26006d2ae70d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': ' Yes, Apple is working on large language models.\\n',\n",
              " 'sources': 'https://jobs.apple.com/en-us/details/200478486/natural-language-generation-research-engineer-input-experience?team=MLAI, https://jobs.apple.com/en-us/details/200482795/aiml-software-engineer-machine-learning-platform-intelligence?team=MLAI'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNb8C3gIH1Syp38QjFU/BOo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
